{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TP MAP6009\n",
        "* Objectif: Prédire le risque de rotation\n",
        "* Auteurs:\n",
        "  * Fezeu Ghomsi Eugene Clotaire\n",
        "  * Moussa\n",
        "* Depot: [github.com/fez2010/tp_map6014](https://github.com/fez2010/tp_map6014)"
      ],
      "metadata": {
        "id": "OkTyJQy2DkXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/os-release"
      ],
      "metadata": {
        "id": "dA074-1n-nhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce95b89e-6c04-485a-fdf5-9847bea47b19"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRETTY_NAME=\"Ubuntu 22.04.3 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION_ID=\"22.04\"\n",
            "VERSION=\"22.04.3 LTS (Jammy Jellyfish)\"\n",
            "VERSION_CODENAME=jammy\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "UBUNTU_CODENAME=jammy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn[stats]\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install sklearn\n",
        "!pip install imblearn\n",
        "!pip install joblib"
      ],
      "metadata": {
        "id": "iYavoK8f6hJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b0a4c8-3bdf-40a1-d2df-4d4d8346eeef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn[stats] in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn[stats]) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn[stats]) (2.1.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn[stats]) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from seaborn[stats]) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.12 in /usr/local/lib/python3.10/dist-packages (from seaborn[stats]) (0.14.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn[stats]) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn[stats]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn[stats]) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn[stats]) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn[stats]) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn[stats]) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn[stats]) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn[stats]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn[stats]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn[stats]) (2024.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12->seaborn[stats]) (0.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.12->seaborn[stats]) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.10/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn3c3dlKzQnf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, ShuffleSplit,cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, auc\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from joblib import dump, load\n",
        "from pathlib import Path\n",
        "import os\n",
        "import platform\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(platform.machine(), platform.system(),platform.node(), platform.python_version(), platform.python_compiler(), platform.architecture())"
      ],
      "metadata": {
        "id": "f-fgRxNHHJ0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mpl.set_loglevel(\"debug\")\n",
        "if platform.system() == 'Linux':\n",
        "  font_paths = mpl.font_manager.findSystemFonts()\n",
        "  for font_file in font_paths:\n",
        "    mpl.font_manager.fontManager.addfont(font_file)\n",
        "\n",
        "plt.rcParams['font.family'] = 'Arial'\n",
        "plt.rcParams['font.sans-serif'] = 'Arial'\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['figure.figsize'] = (3.1, 3)\n"
      ],
      "metadata": {
        "id": "U4GDoWYnE3KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"white\", rc={\"grid.linewidth\": 0.1, 'figure.figsize':(3.1,3)})\n",
        "sns.set_style(\"ticks\")\n",
        "sns.set(font='Arial')\n",
        "sns.set_context(\"paper\", font_scale=0.9)\n",
        "#plt.figure(figsize=(3.1, 3))\n",
        "#sns.despine(left=False, bottom=False)"
      ],
      "metadata": {
        "id": "YDdkug2FvVAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def in_ggole_colab():\n",
        "  return os.getenv(\"COLAB_RELEASE_TAG\") != None\n",
        "def set_title(fig, title):\n",
        "  if(in_ggole_colab()):\n",
        "    fig.set_title(title)\n",
        "def title(fig, title):\n",
        "  if(in_ggole_colab()):\n",
        "    fig.title(title)\n",
        "def save_figure(fig,name):\n",
        "  prefix = './outputs/images/'\n",
        "  svg_prefix = f'{prefix}svg/'\n",
        "  png_prefix = f'{prefix}png/'\n",
        "  eps_prefix = f'{prefix}eps/'\n",
        "  pdf_prefix = f'{prefix}pdf/'\n",
        "  prefixs = [svg_prefix, png_prefix, eps_prefix, pdf_prefix]\n",
        "  prefixs_names = ['svg', 'png', 'eps', 'pdf']\n",
        "  for p in prefixs:\n",
        "    Path(p).mkdir(parents=True, exist_ok=True)\n",
        "  for i in range(len(prefixs)):\n",
        "    fig.savefig(f'{prefixs[i]}{name}.{prefixs_names[i]}', format=prefixs_names[i], bbox_inches='tight', dpi=96)\n"
      ],
      "metadata": {
        "id": "aCHnQrnWdZXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture des données depuis le dépot distant"
      ],
      "metadata": {
        "id": "89aN6X7XvMvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILES_PATHS = ['https://raw.githubusercontent.com/fez2010/tp_map6014/refs/heads/main/datasets/turnover.csv','https://raw.githubusercontent.com/fez2010/tp_map6014/refs/heads/main/datasets/turnover_prepared.csv']\n",
        "datasets = []\n",
        "for path in FILES_PATHS:\n",
        "  #get csv file encoding\n",
        "  df = pd.read_csv(path, encoding='Latin-1')\n",
        "\n",
        "  df.columns = df.columns.str.capitalize()\n",
        "  datasets.append(df)\n",
        "\n",
        "print(datasets[1].shape)\n",
        "datasets[0].head()"
      ],
      "metadata": {
        "id": "mOKuUhSmzVye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Création des ensembles de nom\n",
        "CATEGORY_COLUMNS= ['Industry', 'Profession','Traffic', 'Coach', 'Head_gender','Greywage','Way','Gender']\n",
        "QUANTITATIVE_COLUMNS = ['Age','Stag','Novator','Anxiety','Selfcontrol','Independ','Extraversion','Wayencoded']\n",
        "REAL_QUANTITATIVE_COLUMNS = ['Stag', 'Novator','Anxiety','Selfcontrol','Independ','Extraversion']\n",
        "INTEGER_QUANTITATIVE_COLUMNS = ['Age']\n",
        "# Liste des variables explicatives\n",
        "EXPLICATIVES_COLUMNS = CATEGORY_COLUMNS + QUANTITATIVE_COLUMNS\n",
        "# Classe Cible\n",
        "TARGET = 'Event'\n",
        "# Codes Couleur\n",
        "COLOR_PALETTE = ['#8B383F','#373D61','#203AE0']"
      ],
      "metadata": {
        "id": "MwbgyjQmi4EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recherche des valeurs manquantes"
      ],
      "metadata": {
        "id": "pVlbCJVF14Am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(datasets[0].isnull().sum())\n"
      ],
      "metadata": {
        "id": "Oj7UHLcD1jX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(datasets[1].isnull().sum())"
      ],
      "metadata": {
        "id": "6yMkB4cFChfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Liste de valeurs des variables catégoriels\n"
      ],
      "metadata": {
        "id": "s9Bost3byMWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in CATEGORY_COLUMNS:\n",
        "  print(f'Les valeurs de la colonne {column} sont : ',', '.join(datasets[0][column].unique()))\n"
      ],
      "metadata": {
        "id": "Jfi5kS-hyJ0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_description(dataset):\n",
        "  description = dataset.describe(include='all')\n",
        "  description = dataset.describe(include='all')\n",
        "  description.loc['var'] = dataset.var().tolist()\n",
        "  description.loc['skew'] = dataset.skew().tolist()\n",
        "  description.loc['kurt'] = dataset.kurtosis().tolist()\n",
        "  return description\n",
        "print(get_description(datasets[1]))\n",
        "#stats.normaltest(datasets[1][TARGET])\n",
        "Path(\"./outputs/csv/\").mkdir(parents=True, exist_ok=True)\n",
        "get_description(datasets[1]).to_csv('./outputs/csv/stats.csv')\n"
      ],
      "metadata": {
        "id": "wmXixfCZKSVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets[1][TARGET].value_counts()"
      ],
      "metadata": {
        "id": "E1x5VuWmWNAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.values\n"
      ],
      "metadata": {
        "id": "oT9hsN01AWBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphe de la repartion des données par classe\n",
        "with sns.axes_style(\"ticks\"):\n",
        "  splot = plt.pie(data, labels=['Rotation', 'Pas de rotation'], colors=COLOR_PALETTE, autopct='%.0f%%')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  save_figure(plt, 'dataset_pie_chart')\n",
        "  title(plt,'Répartition des données par classes')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "Myoutb4xiyQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sns.axes_style(\"ticks\"):\n",
        "  for column in INTEGER_QUANTITATIVE_COLUMNS + CATEGORY_COLUMNS:\n",
        "    splot = sns.displot(\n",
        "        datasets[1],\n",
        "        x=column, hue=TARGET,\n",
        "        multiple=\"stack\",\n",
        "        palette=COLOR_PALETTE[0:1],\n",
        "        edgecolor=\".3\",\n",
        "        linewidth=.7,\n",
        "        stat=\"probability\",\n",
        "        log_scale=False,\n",
        "    )\n",
        "\n",
        "    x_ticks = [int(x) for x in datasets[1][column].unique()]\n",
        "    splot.ax.set_xticks( [min(x_ticks), int(datasets[1][column].mean()) ,max(x_ticks)])\n",
        "    plt.axvline(datasets[1][column].median(), color=COLOR_PALETTE[2],linestyle='--', label='Médiane')\n",
        "    splot.legend.remove()\n",
        "    splot.ax.set_ylabel(\"Probabilité\")\n",
        "    splot.ax.set_xlabel(\"\")\n",
        "    #splot.ax.set_title(f\"Distribution des valeurs de la colonne {column}\")\n",
        "    save_figure(splot, f'distribution_{column}')\n",
        "    set_title(splot.ax,f'Distribution des valeurs de la colonne {column}')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iMONPWnAOqQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "isaT0rljMVs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sns.axes_style(\"ticks\"):\n",
        "  for column in REAL_QUANTITATIVE_COLUMNS:\n",
        "    plt.figure(figsize=(3.1, 3))\n",
        "    splot = sns.displot(data=datasets[1], x=column, kind=\"kde\",palette=COLOR_PALETTE,  bw_adjust=.25)\n",
        "\n",
        "    plt.legend().remove()\n",
        "    x_ticks = [int(x) for x in datasets[1][column].unique()]\n",
        "    splot.ax.set_xticks( [min(x_ticks), int(datasets[1][column].mean()) ,max(x_ticks)])\n",
        "    plt.axvline(datasets[1][column].median(), color=COLOR_PALETTE[2],linestyle='--', label='Médiane')\n",
        "    splot.ax.set_ylabel(\"Densité\")\n",
        "    splot.ax.set_xlabel(\"\")\n",
        "    #splot.ax.set_title(f\"Distribution de la densité des valeurs de la colonne {column}\")\n",
        "    save_figure(splot, f'density_distribution_{column}')\n",
        "    set_title(splot.ax,f'Distribution de la densité des valeurs de la colonne {column}')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "OvXdUINijZwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Détection des outliers\n",
        "Test de la meilleur des manieres de supprimer les outliers entre IQR et Z-score avec seuil manuel"
      ],
      "metadata": {
        "id": "U-7FmNUTc69U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalisation des données"
      ],
      "metadata": {
        "id": "eyvuJ3JlCnQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "f_scaler = scaler\n",
        "b = datasets[1].copy()\n",
        "b[EXPLICATIVES_COLUMNS] = scaler.fit_transform(b[EXPLICATIVES_COLUMNS])"
      ],
      "metadata": {
        "id": "BIdlXPrz87q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identification des colonnes qui ont des outliers"
      ],
      "metadata": {
        "id": "IQR-KdCFM_wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with sns.axes_style(\"ticks\"):\n",
        "  b[QUANTITATIVE_COLUMNS].boxplot(figsize=(3.1, 3))\n",
        "  plt.xticks(rotation=90)\n",
        "  save_figure(plt, f'main_boxplot_show_outlier_columns')\n",
        "  title(plt,'Identification des colonnes présentant des anomalies')\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "5yPPbjaT9m6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Détection des outliers avec IQR"
      ],
      "metadata": {
        "id": "S5_MCrgDKRrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IQR_dataset = b.copy()"
      ],
      "metadata": {
        "id": "3JYJyOwMGfHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colonnes présentant des outliers\n",
        "columns = ['Stag','Age']\n",
        "REMOVED_COLUMNS_INDEX = []\n",
        "with sns.axes_style(\"ticks\"):\n",
        "      IQR_dataset[columns].boxplot(figsize=(3.1, 3))\n",
        "      plt.xticks(rotation=90)\n",
        "      save_figure(plt, f'boxplot_show_outlier_column_{column}')\n",
        "      plt.show()\n",
        "\n",
        "def remove_outliers(IQR_dataset, columns):\n",
        "  for column in columns:\n",
        "    # EIQ\n",
        "    Q1 = np.percentile(IQR_dataset[column], 25, method='midpoint')\n",
        "    Q3 = np.percentile(IQR_dataset[column], 75, method='midpoint')\n",
        "    IQR = Q3 - Q1\n",
        "    print(f\"EIQ de la colonne {column} \", IQR)\n",
        "\n",
        "    # Limite supérieur\n",
        "    upper = Q3+1.5*IQR\n",
        "    upper_array = np.array(IQR_dataset[column] >= upper)\n",
        "    print(f\"Limite supérieur de la colonne {column}:\", upper)\n",
        "    print(upper_array.sum())\n",
        "\n",
        "    # Limite inférieur\n",
        "    lower = Q1-1.5*IQR\n",
        "    lower_array = np.array(IQR_dataset[column] <= lower)\n",
        "    print(f\"Limite inférieur de la colonne {column}:\", lower)\n",
        "    print(lower_array.sum())\n",
        "\n",
        "\n",
        "    # Création du tableau Boolean indiquant les lignes ayant des outliers\n",
        "    upper_array = np.where(IQR_dataset[column] >= upper)[0]\n",
        "    lower_array = np.where(IQR_dataset[column] <= lower)[0]\n",
        "    with sns.axes_style(\"ticks\"):\n",
        "      IQR_dataset[[column]].boxplot(figsize=(3.1, 3))\n",
        "      plt.xticks(rotation=90)\n",
        "      plt.axhline(upper, color='red', linestyle='--', label=\"Limites\")\n",
        "      plt.axhline(lower, color='red', linestyle='--', )\n",
        "      save_figure(plt, f'boxplot_show_outlier_column_{column}')\n",
        "      plt.show()\n",
        "\n",
        "    REMOVED_COLUMNS_INDEX = np.concatenate((upper_array, lower_array))\n",
        "    REMOVED_COLUMNS_INDEX = np.unique(np.array(REMOVED_COLUMNS_INDEX.tolist(), dtype=np.int16)).tolist()\n",
        "    # Suppression des outliers\n",
        "    IQR_dataset.drop(index=upper_array, inplace=True)\n",
        "    IQR_dataset.drop(index=lower_array, inplace=True)\n",
        "    IQR_dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Afficher la nouvelle taille du  DataFrame\n",
        "    print(f\"Nouvelle taille apres suppression des outliers sur la colonne {column}: \", IQR_dataset.shape)\n",
        "\n",
        "  return IQR_dataset\n",
        "IQR_dataset = remove_outliers(IQR_dataset, columns)\n",
        "#IQR_dataset = remove_outliers(IQR_dataset, columns)\n",
        "#IQR_dataset = remove_outliers(IQR_dataset, columns)\n",
        "with sns.axes_style(\"ticks\"):\n",
        "      IQR_dataset[columns].boxplot(figsize=(3.1, 3))\n",
        "      plt.xticks(rotation=90)\n",
        "      save_figure(plt, f'boxplot_show_outlier_removed_on_columns')\n",
        "      plt.show()\n"
      ],
      "metadata": {
        "id": "04hXpoSyJxBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sns.axes_style(\"ticks\"):\n",
        "  IQR_dataset[QUANTITATIVE_COLUMNS].boxplot(figsize=(3.1, 3))\n",
        "  plt.xticks(rotation=90)\n",
        "  #plt.tight_layout()\n",
        "  save_figure(plt, f'main_boxplot_show_outlier_removed_on_columns')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "I53PrIocKcGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IQR_dataset.shape"
      ],
      "metadata": {
        "id": "Xl0fKf-XW8Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sns.axes_style(\"ticks\"):\n",
        "  plt.figure(figsize=(13, 6))\n",
        "  mask = np.triu(np.ones_like(IQR_dataset.corr()))\n",
        "  mask[0][0] = False\n",
        "  mask[mask.shape[0]-1][mask.shape[1]-1] = False\n",
        "  heatmap = sns.heatmap(IQR_dataset.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
        "  plt.tight_layout()\n",
        "  plt.box(False)\n",
        "  save_figure(plt, 'corr_heatmap_after_removing_outlier')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "gF5RHxcMiKDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Détection des outliers avec Z-score"
      ],
      "metadata": {
        "id": "66NNwsTmYQAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ZScore_dataset = datasets[1].copy()"
      ],
      "metadata": {
        "id": "Y0N2QInVYl51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ZScore_dataset[EXPLICATIVES_COLUMNS] = scaler.fit_transform(ZScore_dataset[EXPLICATIVES_COLUMNS])\n",
        "with sns.axes_style(\"ticks\"):\n",
        "  ZScore_dataset[QUANTITATIVE_COLUMNS].boxplot()\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "hNk1carKYsep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_threshold_z = datasets[1]['Age'].std() * 2.8"
      ],
      "metadata": {
        "id": "glkQKcmZ5SVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_indices = np.where(ZScore_dataset['Stag'] > 2.2)[0]\n",
        "print(outlier_indices)\n",
        "REMOVED_COLUMNS_INDEX  = np.concatenate((REMOVED_COLUMNS_INDEX, outlier_indices))\n",
        "REMOVED_COLUMNS_INDEX = np.unique(np.array(REMOVED_COLUMNS_INDEX.tolist(), dtype=np.int16)).tolist()\n",
        "no_outliers = ZScore_dataset.drop(outlier_indices)\n",
        "print(\"Original DataFrame Shape:\", ZScore_dataset.shape)\n",
        "print(\"DataFrame Shape after Removing Outliers:\", no_outliers.shape)"
      ],
      "metadata": {
        "id": "Wogm_Y8l6Mzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sns.axes_style(\"ticks\"):\n",
        "  no_outliers[QUANTITATIVE_COLUMNS].boxplot()\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.show()\n",
        "no_outliers.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "TurZQ_1l7r-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_z = 2.8\n",
        "\n",
        "outlier_indices = np.where(no_outliers['Age'] > threshold_z)[0]\n",
        "print(outlier_indices, )\n",
        "REMOVED_COLUMNS_INDEX  = np.concatenate((REMOVED_COLUMNS_INDEX, outlier_indices))\n",
        "REMOVED_COLUMNS_INDEX = np.unique(np.array(REMOVED_COLUMNS_INDEX.tolist(), dtype=np.int16)).tolist()\n",
        "no_outliers_2 = no_outliers.drop(outlier_indices)\n",
        "print(\"Original DataFrame Shape:\", no_outliers.shape)\n",
        "print(\"DataFrame Shape after Removing Outliers:\", no_outliers_2.shape)"
      ],
      "metadata": {
        "id": "0pXGdJND80W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sns.axes_style(\"ticks\"):\n",
        "  no_outliers_2[QUANTITATIVE_COLUMNS].boxplot()\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "cr4An6xp9E0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_outliers_2.shape"
      ],
      "metadata": {
        "id": "Ybu477AkaoZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sns.axes_style(\"ticks\"):\n",
        "  plt.figure(figsize=(13, 6))\n",
        "  # define the mask to set the values in the upper triangle to True\n",
        "  mask = np.triu(np.ones_like(no_outliers_2.corr()))\n",
        "  mask[0][0] = False\n",
        "  mask[mask.shape[0]-1][mask.shape[1]-1] = False\n",
        "  heatmap = sns.heatmap(no_outliers_2.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
        "  heatmap.bbox_inches = 'with'\n",
        "  plt.tight_layout()\n",
        "  plt.box(False)\n",
        "  save_figure(plt, 'corr_heatmap_after_removing_outlier_2')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "IkZhcQvHpDnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Supression d'une colonne des pairs ayant les memes informations"
      ],
      "metadata": {
        "id": "qCzoaqgRFAb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REMOVED_COLUMNS = ['Wayencoded']\n",
        "CATEGORY_COLUMNS= ['Industry', 'Profession','Traffic', 'Coach', 'Head_gender','Greywage','Way','Gender']\n",
        "QUANTITATIVE_COLUMNS = ['Age','Stag','Novator','Anxiety','Selfcontrol','Independ','Extraversion']\n",
        "EXPLICATIVES_COLUMNS = CATEGORY_COLUMNS + QUANTITATIVE_COLUMNS\n",
        "IQR_dataset = IQR_dataset[EXPLICATIVES_COLUMNS + [TARGET]]\n",
        "no_outliers_2 = no_outliers_2[EXPLICATIVES_COLUMNS + [TARGET]]\n",
        "\n",
        "print(IQR_dataset.shape)\n",
        "print(no_outliers_2.shape)\n",
        "IQR_dataset.head()\n",
        "assert IQR_dataset.shape[1] == no_outliers_2.shape[1] == datasets[1].shape[1] - len(REMOVED_COLUMNS)"
      ],
      "metadata": {
        "id": "CuK5NaAMhYMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IQR_dataset ou ...\n",
        "ACP_dataset = datasets[1].copy()\n",
        "ACP_dataset.drop(index=REMOVED_COLUMNS_INDEX, inplace=True)\n",
        "ACP_dataset.reset_index(drop=True, inplace=True)\n",
        "ACP_dataset.shape"
      ],
      "metadata": {
        "id": "7WzRbxPfkruk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "f_scaler = scaler\n",
        "ACP_dataset[EXPLICATIVES_COLUMNS] = scaler.fit_transform(ACP_dataset[EXPLICATIVES_COLUMNS])"
      ],
      "metadata": {
        "id": "0VtdfxoXlLLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_components_short_names(n):\n",
        "  return [f'C{i+1}' for i in range(n)]\n",
        "\n",
        "print(np.linalg.det(ACP_dataset[EXPLICATIVES_COLUMNS].corr().to_numpy()) *\n",
        "      np.linalg.det(np.transpose(np.linalg.inv(ACP_dataset[EXPLICATIVES_COLUMNS].corr().to_numpy()))))\n",
        "# Créer un objet PCA\n",
        "pca = PCA(random_state=0)\n",
        "\n",
        "# Appliquer l'ACP aux données standardisées\n",
        "pca.fit(ACP_dataset[EXPLICATIVES_COLUMNS])\n",
        "\n",
        "# Composantes principales\n",
        "components = pca.components_\n",
        "\n",
        "# Variance expliquée\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "# Matrice des valeurs propres (Importance des facteurs)\n",
        "eigenvalues = pca.explained_variance_\n",
        "\n",
        "# Vecteurs propres (Construction des facteurs)\n",
        "eigenvectors = pca.components_\n",
        "\n",
        "# Contributions des variables aux composantes principales 1 et 2\n",
        "contributions = pca.components_[:2, :].T\n",
        "\n",
        "# Noms des variables\n",
        "variable_names = ACP_dataset[EXPLICATIVES_COLUMNS].columns\n",
        "\n",
        "# Matrice des valeurs propres\n",
        "# Saturations (Importance des variables / facteurs)\n",
        "loadings = eigenvectors * np.sqrt(eigenvalues.reshape(-1, 1))\n",
        "with sns.axes_style(\"ticks\"):\n",
        "  # Créez un graphique de dispersion des contributions\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.scatter(contributions[:, 0], contributions[:, 1], marker='o', color='blue', alpha=0.5)\n",
        "  plt.xlabel('Contribution à C1')\n",
        "  plt.ylabel('Contribution à C2')\n",
        "  save_figure(plt, f'dispertion_of_variable_contribution_to_composent_one_and_two')\n",
        "\n",
        "  # Ajoutez les noms des variables\n",
        "  for i, variable in enumerate(variable_names):\n",
        "      plt.annotate(variable, (contributions[i, 0], contributions[i, 1]))\n",
        "\n",
        "  plt.title('Contributions des Variables aux Composantes Principales 1 et 2')\n",
        "  plt.grid(color='white', linestyle='--', linewidth=0.5)\n",
        "  plt.box(False)\n",
        "  plt.axhline(0, color='black', linewidth=0.5)\n",
        "  plt.axvline(0, color='black', linewidth=0.5)\n",
        "  save_figure(plt, f'variable_contribution_to_composent_one_and_two')\n",
        "  plt.show()\n",
        "\n",
        "  # Visualisation des valeurs propres par pourcentage expliquer\n",
        "  plt.figure(figsize=(3.1, 3))\n",
        "  plt.bar(range(1, len(eigenvalues) + 1), explained_variance *100, alpha=0.5, align='center')\n",
        "  plt.axhline(1, color='red', linestyle='--', label=\"Seuil de signifiance\")\n",
        "  plt.xlabel('Composante Principale')\n",
        "  plt.ylabel('Valeur Propre')\n",
        "  plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "\n",
        "  save_figure(plt, f'bar_show_prinpal_components')\n",
        "  plt.show()\n",
        "  # Visualisation des valeurs propres\n",
        "  plt.figure(figsize=(3.1, 3))\n",
        "  plt.bar(range(1, len(eigenvalues) + 1), eigenvalues, alpha=0.5, align='center')\n",
        "  plt.axhline(1, color='red', linestyle='--', label=\"Seuil d'importance\")\n",
        "  plt.xlabel('Composante Principale')\n",
        "  plt.ylabel('Valeur Propre')\n",
        "  plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "\n",
        "  save_figure(plt, f'bar_show_principal_component_column_s')\n",
        "  plt.show()\n",
        "imp = pd.DataFrame(data = { 'TVE': eigenvalues, 'PVTE': explained_variance*100, 'CumPVTE': np.cumsum(explained_variance*100) },  index=generate_components_short_names(len(eigenvalues)))\n",
        "imp.to_csv('./outputs/csv/acp_imp.csv')\n",
        "imp\n",
        "\n"
      ],
      "metadata": {
        "id": "IsCdhMJkG7ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Nombre de composantes choisie\n",
        "n = 7\n",
        "pca = PCA(n_components=n, random_state=0)\n",
        "sm = SVMSMOTE(random_state=0)\n",
        "\n",
        "# Appliquer l'ACP aux données standardisées\n",
        "\n",
        "reduced_ACP_dataset = pca.fit_transform(ACP_dataset[EXPLICATIVES_COLUMNS])\n",
        "reduced_ACP_dataset = pd.DataFrame(data=reduced_ACP_dataset, columns=generate_components_short_names(n))\n",
        "reduced_ACP_dataset[TARGET] = ACP_dataset[TARGET]\n",
        "\n",
        "# Composantes principales\n",
        "components = pca.components_\n",
        "\n",
        "# Corretion du déséquilibre\n",
        "X, y = sm.fit_resample(reduced_ACP_dataset[generate_components_short_names(n)], reduced_ACP_dataset[TARGET])\n",
        "print(X.shape)\n",
        "# Diviser le dataset en ensembles d'entraînement et de test\n",
        "cv = ShuffleSplit(n_splits=500, test_size=0.3, random_state=0)\n",
        "\n",
        "# Créer un modèle de régression logistique avec régularisation L2 (Ridge)\n",
        "alpha = 1  # Paramètre de régularisation, ajustez selon vos besoins\n",
        "model = LogisticRegression( penalty='l2', solver='newton-cg', random_state=0, C=1/alpha, max_iter=1000)\n",
        "\n",
        "scoring = ['precision_micro', 'roc_auc','recall','accuracy','f1_micro']\n",
        "# Entraîner le modèle sur les données d'entraînement\n",
        "scores = cross_validate(model, X, y, cv=cv, scoring=scoring,return_train_score=True, return_estimator=True,  return_indices=True)\n",
        "print(scores.keys(),\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores['test_accuracy'].mean(), scores['test_roc_auc'].std()))\n",
        "\n",
        "# Sélection du meilleur estimateur (test_recall, test_f1_micro, test_precision_micro, test_accuracy, test_roc_auc)\n",
        "index = [np.where(scores['test_recall']==scores['test_recall'].max())[0],np.where(scores['test_f1_micro']==scores['test_f1_micro'].max())[0],np.where(scores['test_precision_micro']==scores['test_precision_micro'].max())[0], np.where(scores['test_accuracy']==scores['test_accuracy'].max())[0],np.where(scores['test_roc_auc']==scores['test_roc_auc'].max())[0]]\n",
        "print(index)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iFw-fRoMYr_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Index = np.concatenate(index)\n",
        "Index = np.unique(np.array(Index.tolist(), dtype=np.int16)).tolist()\n",
        "def generate_estimator_short_names(n):\n",
        "  return [f'E{i+1}' for i in range(n)]\n",
        "\n",
        "estimators_names = generate_estimator_short_names(len(Index))\n",
        "Metrics = ['test_recall', 'test_f1_micro', 'test_precision_micro', 'test_accuracy', 'test_roc_auc']\n",
        "Performances = {'#Indices': []}\n",
        "maxI = 0\n",
        "metricMax = 'test_accuracy'\n",
        "for i in range(len(Metrics)):\n",
        "  Performances[Metrics[i]] = []\n",
        "  for j in range(len(Index)):\n",
        "    Performances[Metrics[i]].append(scores[Metrics[i]][Index[j]])\n",
        "    Performances['#Indices'].append(Index[j])\n",
        "for i in range(len(Index)):\n",
        "  if Performances[metricMax][i] > Performances[metricMax][maxI]:\n",
        "    maxI = i\n",
        "es = pd.DataFrame(Performances,columns=Metrics, index=estimators_names)\n",
        "\n",
        "es.columns =  es.columns.str.capitalize()\n",
        "es.columns =  es.columns.str.replace('_', ' ')\n",
        "es['#Indice'] = Index\n",
        "es.to_csv('./outputs/csv/estimator_scores.csv')\n",
        "es\n"
      ],
      "metadata": {
        "id": "s478rs0OMmfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prendre l'estimateur qui a la meilleur courbe roc\n",
        "\n",
        "def get_roc_auc(scores, index, Fclass):\n",
        "  model = scores['estimator'][index]\n",
        "  X_test = X.iloc[scores['indices']['test'][index]]\n",
        "  y_test = y.iloc[scores['indices']['test'][index]]\n",
        "  y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  return fpr, tpr, thresholds, roc_auc\n",
        "with sns.axes_style(\"ticks\"):\n",
        "  plt.figure(figsize=(3.1, 3))\n",
        "  for index in range(len(Index)):\n",
        "    fpr, tpr, thresholds, roc_auc = get_roc_auc(scores, Index[index], 1)\n",
        "\n",
        "    plt.plot(fpr, tpr,  lw=2, label=f'ROC {estimators_names[index]} (area = %0.2f)' % roc_auc)\n",
        "  plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('Taux de FP')\n",
        "  plt.ylabel('Taux de VP')\n",
        "  title(plt,'Courbe ROC')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "  save_figure(plt, 'roc_curve')"
      ],
      "metadata": {
        "id": "dhQ2L4BMlGti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = scores['estimator'][Index[maxI]]\n",
        "X_test = X.iloc[scores['indices']['test'][Index[maxI]]]\n",
        "y_test = y.iloc[scores['indices']['test'][Index[maxI]]]"
      ],
      "metadata": {
        "id": "I1RVfwVaN1mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Faire des prédictions sur l'ensemble de test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculer les métriques de performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Afficher les métriques de performance\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)"
      ],
      "metadata": {
        "id": "qenPE5k-Nmpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_names = ['VN','FP','FN','VP']\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in conf_matrix.flatten()]\n",
        "group_percentages = ['{0:.2%}'.format(value) for value in conf_matrix.flatten()/np.sum(conf_matrix)]\n",
        "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "with sns.axes_style(\"ticks\"):\n",
        "\n",
        "  splot = sns.heatmap(conf_matrix, annot=labels, fmt='', cmap='Blues')\n",
        "  save_figure(plt,'matrice_confusion_meilleur_estimateur')"
      ],
      "metadata": {
        "id": "7oeQdI6-bEfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauvegarde des models\n",
        "Path(\"./outputs/models/\").mkdir(parents=True, exist_ok=True)\n",
        "dump(model, './outputs/models/model.joblib')\n",
        "dump(f_scaler, './outputs/models/scaler.joblib')\n",
        "dump(pca, './outputs/models/pca.joblib')\n",
        "with open('./outputs/models/model_input_columns_name.txt', 'w') as f:\n",
        "  f.write(','.join(EXPLICATIVES_COLUMNS + REMOVED_COLUMNS))\n",
        "with open('./outputs/models/model_pca_input_columns_name.txt', 'w') as f:\n",
        "  f.write(','.join(EXPLICATIVES_COLUMNS ))"
      ],
      "metadata": {
        "id": "V8D_CNGfnk0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test du chargement des Models et Prediction\n",
        "input_columns = []\n",
        "pca_input_columns = []\n",
        "with open('./outputs/models/model_input_columns_name.txt', 'r') as f:\n",
        "  f.seek(0)\n",
        "  input_columns = f.read().split(',')\n",
        "with open('./outputs/models/model_pca_input_columns_name.txt', 'r') as f:\n",
        "  f.seek(0)\n",
        "  pca_input_columns = f.read().split(',')\n",
        "model = load('./outputs/models/model.joblib')\n",
        "scaler = load('./outputs/models/scaler.joblib')\n",
        "pca = load('./outputs/models/pca.joblib')\n",
        "X_test = datasets[1][input_columns].iloc[1:10]\n",
        "X_test[pca_input_columns] = scaler.transform(datasets[1][pca_input_columns].iloc[1:10])\n",
        "X_test_r = pca.transform(X_test[pca_input_columns])\n",
        "y_pred = model.predict(X_test_r)\n",
        "y_pred_proba = model.predict_proba(X_test_r)\n",
        "print(y_pred, y_pred_proba)"
      ],
      "metadata": {
        "id": "DSnOOS0xRA5j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}